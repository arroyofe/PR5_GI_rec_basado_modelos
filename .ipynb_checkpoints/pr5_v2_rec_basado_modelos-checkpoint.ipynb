{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a680b219-3e44-48f0-b817-bfb60f9339ce",
   "metadata": {},
   "source": [
    "# 1 Instalación de surprise por medio del terminal de anaconda con derechos de administrador\n",
    "## Se introduce la instrucción conda install -c conda-forge scikit-surprise\n",
    "\n",
    "Surprise requiere python 3.10.x no funciona con versiones inferiores o superiores. Se adpata también en consola,\n",
    "instalando python 3.10.19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233741e1-f229-4540-ac2c-7b12c9f0c91d",
   "metadata": {},
   "source": [
    "# 2 Instalación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe328c0d-9e32-433a-b823-f430fcc58cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importación de módulos especificos de surprise\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVD, KNNBasic\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, cross_validate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "# Importación de módulos especificos de surprise\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, KNNBasic\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "\n",
    "# Importación de otras liberías útiles\n",
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlx.frequent_patterns import apriori, association_ruules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f35a603-7eb8-46e0-a300-fe099cba8880",
   "metadata": {},
   "source": [
    "# 3 Importación de datos de movilens\n",
    "## Para mayor simplicidad se ha importado los datos en el fichero dataset.csv con los campos siguientes:\n",
    "* userId\n",
    "* movieId\n",
    "* Title\n",
    "* rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6925b5-d841-47f9-8ef6-9b2f1ae32994",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='userId movieId rating', sep=';')\n",
    "data = Dataset.load_from_file('dataset.csv', reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5eea80-b761-4562-82c8-0914712cc769",
   "metadata": {},
   "source": [
    "# 4 División del fichero entre entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8dc96-b0bf-4a92-ae44-aa032bb8b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # test_size=0.2 significa que 20%  de los datos servirá para el test\n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    print(f\"\\nTraining set size: {len(trainset.all_ratings())}\")\n",
    "    print(f\"Test set size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37940856-2f24-4265-a96c-d77d94479d09",
   "metadata": {},
   "source": [
    "# 5 Entrenamiento del modelo SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002071b-54ac-47aa-b7c0-bd6dbdce346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"\\n Entrenando al modelo SVD...\")\n",
    "    \n",
    "    svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "    svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba26e03-dcc8-48d8-81f3-27272231d58c",
   "metadata": {},
   "source": [
    "# 6 Evaluación del modelo en el set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2ba3a-d744-4658-88d0-fc32da817e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    predictions = svd.test(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    mae = accuracy.mae(predictions)\n",
    "    \n",
    "    print(f\"Evaluación del modelo en el set de test:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\") # RMSE (Root Mean Square Error): valores bajos indican un mejor resultado\n",
    "    print(f\"MAE: {mae:.4f}\") # MAE (Mean Absolute Error): medida de la exactitud de la predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b8b29-3cf7-4ff2-a5b1-242f04999cb1",
   "metadata": {},
   "source": [
    "# 7 Función para obtener las N mejores recomendaciones para un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c25a2-6ef0-4553-9d03-ea1a73eca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_top_n_recommendations(predictions, n=10):\n",
    "        \"\"\"Devuelve las n mejores recomendaciones para cada usuario\n",
    "        en este caso las 10 mejores\"\"\"\n",
    "        # Diccionario con las predicciones para cada usuario\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "            \n",
    "        # Se ordenan las predicciones para cada usuario y se encuentran las mejores\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "            \n",
    "        return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2873b-63bf-4586-860c-2b698aad6040",
   "metadata": {},
   "source": [
    "# 8 Función para generar recomendaciones para un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7246f-bb85-47dc-a4f8-1bcecf140dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def recommend_for_user(user_id, n=10):\n",
    "        \"\"\"Crea n recommendaciones para un usuario espedífico\"\"\"\n",
    "        # Obtener la lista de todos los identificadores de películas\n",
    "        all_movie_ids = ratings_df['movieId'].unique()\n",
    "        \n",
    "        # Obeter los identificadores de las películas que el usuario ya ha visto\n",
    "        user_rated_movies = set(ratings_df[ratings_df['userId'] == user_id]['movieId'])\n",
    "        \n",
    "        # Identificadores de las películas que el usuario no ha visto para hacer predicciones\n",
    "        movies_to_predict = [movie_id for movie_id in all_movie_ids if movie_id not in user_rated_movies]\n",
    "        \n",
    "        # Hacer predicciones\n",
    "        predictions = [svd.predict(user_id, movie_id) for movie_id in movies_to_predict]\n",
    "        \n",
    "        # Ordenar las predicciones usanto evaluaciones estimadas\n",
    "        predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        \n",
    "        # Guardar las n mejores y devolverlas\n",
    "        top_recommendations = predictions[:n]\n",
    "        \n",
    "        return top_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1409e-bae0-499e-84ee-431827308825",
   "metadata": {},
   "source": [
    "# 9 Predicción para un usuario determinado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72f9f2-d86f-4f2c-b934-83604a9effe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Choose a user that exists in your dataset\n",
    "    sample_user = ratings_df['userId'].iloc[0]\n",
    "    print(f\"\\nGenerando recommendaciones para el user {sample_user}...\")\n",
    "    \n",
    "    recommendations = recommend_for_user(sample_user, n=10)\n",
    "    \n",
    "    print(f\"\\n 10 películas recommendadas para el usuario {sample_user}:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        movie_id = rec.iid\n",
    "        predicted_rating = rec.est\n",
    "        title = movie_titles.get(movie_id, f\"Identificador de la película: {movie_id}\")\n",
    "        print(f\"{i}. {title} (Evaluación prevista: {predicted_rating:.2f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971cc59-9ea3-4d2e-8641-0ab7eabe62e7",
   "metadata": {},
   "source": [
    "# 10 Archivar el modelo para usos futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b10e96-c276-4cef-b9cf-df42513930c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pickle\n",
    "    with open('svd_model.pkl', 'wb') as file:\n",
    "        pickle.dump(svd, file)\n",
    "    \n",
    "    print(\"\\nModelo guradado como 'svd_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a804cc-6845-4bef-a48d-be8fcc38d315",
   "metadata": {},
   "source": [
    "## Notes on the Implementation\n",
    "\n",
    "1. **SVD Algorithm**: Surprise's SVD implementation is a matrix factorization algorithm optimized for recommendation systems. It's similar to the algorithm that won the Netflix Prize.\n",
    "\n",
    "2. **Hyperparameters**:\n",
    "   - `n_factors`: Number of latent factors (dimensions)\n",
    "   - `n_epochs`: Number of iterations over the training data\n",
    "   - `lr_all`: Learning rate for all parameters\n",
    "   - `reg_all`: Regularization term for all parameters\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - RMSE (Root Mean Square Error): Lower values indicate better performance\n",
    "   - MAE (Mean Absolute Error): Another measure of prediction accuracy\n",
    "\n",
    "4. **Recommendation Functions**:\n",
    "   - `get_top_n_recommendations`: Gets top N recommendations for all users\n",
    "   - `recommend_for_user`: Gets recommendations for a specific user\n",
    "\n",
    "5. **Cold Start Problem**: This implementation doesn't specifically address the cold start problem (new users or items). For production systems, you might need additional strategies.\n",
    "\n",
    "6. **Model Persistence**: The model is saved using pickle for future use without retraining.\n",
    "\n",
    "## Improving the Model\n",
    "\n",
    "To improve the model's performance, you could:\n",
    "\n",
    "1. **Tune hyperparameters** using grid search or random search\n",
    "2. **Try different algorithms** like NMF, KNNBasic, or KNNWithMeans\n",
    "3. **Add content-based features** if you have movie metadata\n",
    "4. **Implement hybrid approaches** combining collaborative filtering with content-based methods\n",
    "5. **Use cross-validation** instead of a simple train/test split\n",
    "\n",
    "This implementation provides a solid foundation for a recommendation system that you can build upon and refine based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66338343-4443-40f7-ac66-b1864307c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Conversión usando DataFrames de los sets de entrenamiento y test guardados como CSV\n",
    "    # Set de entrenamiento\n",
    "    train_users, train_items, train_ratings = [], [], []\n",
    "    for (uid, iid, rating) in trainset.all_ratings():\n",
    "        # Map internal ids back to raw ids\n",
    "        user = trainset.to_raw_uid(uid)\n",
    "        item = trainset.to_raw_iid(iid)\n",
    "        train_users.append(user)\n",
    "        train_items.append(item)\n",
    "        train_ratings.append(rating)\n",
    "    \n",
    "    train_df = pd.DataFrame({\n",
    "        'userId': train_users,\n",
    "        'movieId': train_items,\n",
    "        'rating': train_ratings\n",
    "    })\n",
    "    \n",
    "    # Set de test\n",
    "    test_users = [uid for (uid, _, _) in testset]\n",
    "    test_items = [iid for (_, iid, _) in testset]\n",
    "    test_ratings = [r for (_, _, r) in testset]\n",
    "    \n",
    "    test_df = pd.DataFrame({\n",
    "        'userId': test_users,\n",
    "        'movieId': test_items,\n",
    "        'rating': test_ratings\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    train_df.to_csv('movielens_train_surprise.csv', index=False)\n",
    "    test_df.to_csv('movielens_test_surprise.csv', index=False)\n",
    "    \n",
    "    print(\"\\nFicheros guardados como'movielens_train_surprise.csv' y 'movielens_test_surprise.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ddbdf6-d7c8-4e28-8673-aa3dd4965030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba28a8d-13df-4225-80a5-e95dae167f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
